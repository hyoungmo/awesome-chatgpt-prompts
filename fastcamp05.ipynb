{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMux1+UKceuMhfRBkvXsfBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyoungmo/awesome-chatgpt-prompts/blob/main/fastcamp05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yciHxk19rNYt",
        "outputId": "950137a5-d2f6-48f5-f484-0f9eb02ca00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.7.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m762.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.7.0 typing-extensions-4.9.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=046426a16c1e72478e05f211a1860d8bb2382297bceff5e04359507e7156c9d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install requests\n",
        "!pip install bs4\n",
        "\n",
        "import openai\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://finance.naver.com/sise/sise_group.naver?type=upjong'\n",
        "\n",
        "res = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(res.content, 'html.parser')\n",
        "\n",
        "text = soup.find_all(string=True)\n",
        "\n",
        "except_tags = ['[document]', 'title', 'noscript', 'header', 'html', 'meta', 'head', 'input','script', 'style']\n",
        "\n",
        "output = ''\n",
        "for t in text:\n",
        "    if t.parent.name not in except_tags:\n",
        "        output += '{} '.format(t)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "lEkSm25vvzPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "except_tags = ['[document]', 'title', 'noscript', 'header', 'html', 'meta', 'head', 'input','script', 'style']\n",
        "\n",
        "def scrap_web(url: str):\n",
        "    res = requests.get(url)\n",
        "    soup = BeautifulSoup(res.content, 'html.parser')\n",
        "    text = soup.find_all(string=True)\n",
        "\n",
        "    text_all = ''\n",
        "    for t in text:\n",
        "        if t.parent.name not in except_tags:\n",
        "            text_all += '{} '.format(t)\n"
      ],
      "metadata": {
        "id": "55FWxNDMv-ZE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_stock_status(content, temperature=0, max_tokens=2048):\n",
        "#     user_message = f\"\"\"다음은 주가 정보 페이지를 복사해 온 정보야. 다음 정보에서 주가 업종과 시세, 등락 정보를 추출해서 표로 만들어줘.\n",
        "# {content}\n",
        "# \"\"\"\n",
        "    user_message = f\"\"\"다음은 주가 정보 페이지를 복사해 온 정보야. 다음 정보에서 주가 업종과 시세, 등락 정보를 추출해서 JSON 포맷으로 만들어줘. 최상위 10개만 출력해줘.\n",
        "{content}\n",
        "\"\"\"\n",
        "\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_message\n",
        "            }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "Q8_ZHnAGwT6l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://finance.naver.com/sise/sise_group.naver?type=upjong'\n",
        "\n",
        "web_text = scrap_web(url)\n",
        "\n",
        "result = extract_stock_status(web_text)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6veMhWr8wt-l",
        "outputId": "a3ff0018-0d58-44ca-f9b4-5f61053689e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"업종\": \"반도체\",\n",
            "      \"시세\": \"100,000\",\n",
            "      \"등락\": \"+1,000\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"화학\",\n",
            "      \"시세\": \"50,000\",\n",
            "      \"등락\": \"-500\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"자동차\",\n",
            "      \"시세\": \"200,000\",\n",
            "      \"등락\": \"+2,500\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"은행\",\n",
            "      \"시세\": \"80,000\",\n",
            "      \"등락\": \"-1,200\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"바이오\",\n",
            "      \"시세\": \"150,000\",\n",
            "      \"등락\": \"+3,000\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"건설\",\n",
            "      \"시세\": \"70,000\",\n",
            "      \"등락\": \"-800\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"통신\",\n",
            "      \"시세\": \"120,000\",\n",
            "      \"등락\": \"+1,500\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"금융\",\n",
            "      \"시세\": \"90,000\",\n",
            "      \"등락\": \"-1,000\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"소프트웨어\",\n",
            "      \"시세\": \"180,000\",\n",
            "      \"등락\": \"+2,000\"\n",
            "    },\n",
            "    {\n",
            "      \"업종\": \"에너지\",\n",
            "      \"시세\": \"60,000\",\n",
            "      \"등락\": \"-700\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}